{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어처리라 함은, 좁은 의미로 텍스트 다루는 내용. 정규표현식, 정규화 코드까지 한번에 다 다룰 예정.\n",
    "뭐 책으로 나온거도 있고, 공부 따로 할만 하다. 베이직한 부분만 긁어옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list / t = s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: a man in the house...>\n",
      "<Text: a   m a n   i n...>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nltk.Text(t)\n",
    "b = nltk.Text(s)\n",
    "print(a)\n",
    "print(b)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlkt 모듈의 Text 함수. 툴킷에서 쓸 수 있는 별도 자료형으로 변환. 일반 스트링하곤 다른.\n",
    "\n",
    "만약 토큰화되지 않은 일반 스트링을 넣을 경우, split('')한거처럼 각 글자 쪼갠 다음에 텍스트함수에 넣어서 그 사이에 다 스페이스 넣는듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: a man in the house...>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nltk.Text(s.split())\n",
    "print(b)\n",
    "type (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고로, 꼭 스플릿으로 토큰화 시킨 스트링을 넣어줄 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read() #죄와벌 텍스트파일임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r 이 뭔 뜻이었더라? -> raw text라는 것. \n",
    "\n",
    "### 이 설정이 붙은 문자열에서는 이스케이프 문자를 적용하지 말라는 뜻임! 그래야 디렉토리 적기가 편하니까.\n",
    "\n",
    "getcwd는 뭐 작업폴더 가져오라는거고 / 인코딩 설정은 utf8 도 ㅇㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1154507\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:75]) #헷갈릴 수 있는데, 이거 인덱스 75까지 보는거 맞음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "257726\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize함수, 스플릿보다 세련된 처리 - 메소드가 아니라 함수고, 논항은 지네 텍스트 타입 변수. 스플릿하곤 다르게 자연어가 아닌거도 분리시켜줌. title, : , ~~ 식으로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "l = text.collocations() #해당 코퍼스 내에서 서로 같이 나오는 두 단어들을 짝지어서 return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.collocations.BigramCollocationFinder( ~~~~ )하는 식의 문법이 있는거 같은데, 더 알아보아야 할 듯.\n",
    "collocations 자체도 nltk 하위 모듈임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-e75269d816bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collocations 자체의 return은 그냥 프린트 시킨거나 매한가지, 변수에 값 할당 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 162 matches:\n",
      "and were more frequent in periods of great strain . In 1859 he was allowed to r\n",
      "ndency and of late she had read with great interest a book she got through Mr. \n",
      " the bosom of her family ... . And a great deal more ... . Quite excusable , si\n",
      "that you had heard that Dounia had a great deal to put up with in the Svidrigra\n",
      "g will she has . Dounia can endure a great deal and even in the most difficult \n",
      " that letter she reproached him with great heat and indignation for the basenes\n",
      "putation ; they had seen and known a great deal more than Mr. Svidrigailov had \n",
      "n other people ’ s . In my opinion a great deal , a very great deal of all this\n",
      " In my opinion a great deal , a very great deal of all this was unnecessary ; b\n",
      " . He is a very busy man and is in a great hurry to get to Petersburg , so that\n",
      " me that , though he is not a man of great education , he is clever and seems t\n",
      " very well . Of course , there is no great love either on his side , or on hers\n",
      "tted the matter has been arranged in great haste . Besides he is a man of great\n",
      "great haste . Besides he is a man of great prudence and he will see , to be sur\n",
      "d that she is ready to put up with a great deal , if only their future relation\n",
      " off for Petersburg , where he has a great deal of business , and he wants to o\n",
      "a or I breathed a word to him of the great hopes we have of his helping us to p\n",
      "ites that ‘ Dounia can put up with a great deal. ’ I know that very well . I kn\n",
      "at , that ‘ Dounia can put up with a great deal. ’ If she could put up with Mr.\n",
      "it , she certainly can put up with a great deal . And now mother and she have t\n",
      "e young , and she was walking in the great heat bareheaded and with no parasol \n",
      "f the skirt , close to the waist : a great piece was rent and hanging loose . A\n",
      "ts or conversations . He worked with great intensity without sparing himself , \n",
      " uproarious and was reputed to be of great physical strength . One night , when\n",
      ". His legs felt suddenly heavy and a great drowsiness came upon him . He turned\n"
     ]
    }
   ],
   "source": [
    "text.concordance('great', 79, 25) #이거 antconc가 하는 그거네.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text.concordance(target_string, 보고자 하는 전체 인덱스 길이, 도출하고자 하는 매칭의 개수)\n",
    "\n",
    "우리가 보고싶어하는 그 단어는 텍스트 내부에 계속 있는 채로 보여줌,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Moby Dick by Herman Melville 1851]\n",
      "\n",
      "\n",
      "ETYMOLOGY.\n",
      "\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
      "\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was\n",
      "[(' ', 198098), ('e', 115855), ('t', 85539), ('a', 75266), ('o', 68338), ('n', 64431), ('s', 62022), ('i', 61891), ('h', 61434), ('r', 51311), ('l', 41893), ('d', 37468), ('u', 26457), ('\\r', 22924), ('\\n', 22924), ('m', 22525), ('c', 21360), ('w', 20917), ('g', 20180), ('f', 20029), (',', 19229), ('y', 16542), ('p', 16207), ('b', 15451), ('v', 8427), ('k', 7882), ('.', 7558), ('-', 5984), (';', 4173), ('I', 3543), ('\"', 3071), (\"'\", 2922), ('A', 2650), ('T', 2457), ('S', 2209), ('!', 1767), ('H', 1462), ('B', 1426), ('W', 1305), ('E', 1237), ('q', 1234), ('N', 1186), ('C', 1147), ('P', 1048), ('x', 1007), ('?', 1004), ('O', 988), ('L', 900), ('j', 829), ('R', 823)]\n",
      "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'a', 'o', 'n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "print(raw[:200])\n",
    "fdist = nltk.FreqDist(raw)\n",
    "print(fdist.most_common(50))\n",
    "\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(fdist.most_common(5))\n",
    "[char for (char, count) in fdist.most_common(5)] #fidst가 튜플 싸고 있는 리스트를 뱉으니까 이렇게 하는거지."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크... 코퍼스다.\n",
    "\n",
    "\n",
    "내장된 예제 데이터임.\n",
    "거기서 FreqDist로 가장 많이 나온 물건들을 긁어올 수 있고.. \n",
    "\n",
    "most_common 어디서 썼었더라??? -> counter module에서 썼었지. 딕셔너리 비슷한 자료형에, 빈도 분석 가능했었음.\n",
    "\n",
    "(ch.lower() for ch in raw if ch.isalpha()) 이 부분은 리스트 내장이랑 신택스가 완전히 같네, nltk 자체 신택스..\n",
    "\n",
    "isalpha는 알파벳이냐는거. 결국 모든 알파벳'만' 긁고 모두 소문자로 바꾸어두겠다는거."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A frequency distribution for the outcomes of an experiment. A frequency distribution records the number of times each outcome of an experiment has occurred. For example, a frequency distribution could be used to record the frequency of each word type in a document. Formally, a frequency distribution can be defined as a function mapping from each sample to the number of times that sample occurred as an outcome.\n",
    "\n",
    "Frequency distributions are generally constructed by running a number of experiments, and incrementing the count for a sample every time it is an outcome of an experiment. For example, the following code will produce a frequency distribution that encodes how often each word occurs in a text:\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "sent = 'This is an example sentence'\n",
    "fdist = FreqDist()\n",
    "for word in word_tokenize(sent):\n",
    "    fdist[word.lower()] += 1\n",
    "\n",
    "An equivalent way to do this is with the initializer:\n",
    "\n",
    "fdist = FreqDist(word.lower() for word in word_tokenize(sent))\n",
    "\n",
    "nltk documentation에서 긁어옴. 이런 식으로 움직이는거니까 참고하시길!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zymosis',\n",
       " 'zymosterol',\n",
       " 'zymosthenic',\n",
       " 'zymotechnic',\n",
       " 'zymotechnical',\n",
       " 'zymotechnics',\n",
       " 'zymotechny',\n",
       " 'zymotic',\n",
       " 'zymotically',\n",
       " 'zymotize',\n",
       " 'zymotoxic',\n",
       " 'zymurgy',\n",
       " 'Zyrenian',\n",
       " 'Zyrian',\n",
       " 'Zyryan',\n",
       " 'zythem',\n",
       " 'Zythia',\n",
       " 'zythum',\n",
       " 'Zyzomys']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
